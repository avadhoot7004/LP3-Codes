

Experiment-5 (Group B): K-Nearest Neighbors algorithm

    import pandas as pd
    import numpy as np
    import seaborn as sns
    import matplotlib.pyplot as plt
    from sklearn.model_selection import train_test_split, GridSearchCV
    from sklearn.preprocessing import StandardScaler
    from sklearn.neighbors import KNeighborsClassifier
    from sklearn.metrics import confusion_matrix, classification_report,accuracy_score
    from sklearn import preprocessing
    import kagglehub
    from kagglehub import KaggleDatasetAdapter

    file_path = "diabetes.csv"

    df = kagglehub.load_dataset(
      KaggleDatasetAdapter.PANDAS,
      "abdallamahgoub/diabetes",
      file_path
    )

    /tmp/ipython-input-156432141.py:3: DeprecationWarning: Use dataset_load() instead of load_dataset(). load_dataset() will be removed in a future version.
      df = kagglehub.load_dataset(

    Using Colab cache for faster access to the 'diabetes' dataset.

    df.info()

    <class 'pandas.core.frame.DataFrame'>
    RangeIndex: 768 entries, 0 to 767
    Data columns (total 9 columns):
     #   Column         Non-Null Count  Dtype  
    ---  ------         --------------  -----  
     0   Pregnancies    768 non-null    int64  
     1   Glucose        768 non-null    int64  
     2   BloodPressure  768 non-null    int64  
     3   SkinThickness  768 non-null    int64  
     4   Insulin        768 non-null    int64  
     5   BMI            768 non-null    float64
     6   Pedigree       768 non-null    float64
     7   Age            768 non-null    int64  
     8   Outcome        768 non-null    int64  
    dtypes: float64(2), int64(7)
    memory usage: 54.1 KB

    df.head()

    {"summary":"{\n  \"name\": \"df\",\n  \"rows\": 768,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 0,\n        \"max\": 17,\n        \"num_unique_values\": 17,\n        \"samples\": [\n          6,\n          1,\n          3\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 31,\n        \"min\": 0,\n        \"max\": 199,\n        \"num_unique_values\": 136,\n        \"samples\": [\n          151,\n          101,\n          112\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BloodPressure\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 19,\n        \"min\": 0,\n        \"max\": 122,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          86,\n          46,\n          85\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"SkinThickness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 15,\n        \"min\": 0,\n        \"max\": 99,\n        \"num_unique_values\": 51,\n        \"samples\": [\n          7,\n          12,\n          48\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 115,\n        \"min\": 0,\n        \"max\": 846,\n        \"num_unique_values\": 186,\n        \"samples\": [\n          52,\n          41,\n          183\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 7.8841603203754405,\n        \"min\": 0.0,\n        \"max\": 67.1,\n        \"num_unique_values\": 248,\n        \"samples\": [\n          19.9,\n          31.0,\n          38.1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pedigree\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.33132859501277484,\n        \"min\": 0.078,\n        \"max\": 2.42,\n        \"num_unique_values\": 517,\n        \"samples\": [\n          1.731,\n          0.426,\n          0.138\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 11,\n        \"min\": 21,\n        \"max\": 81,\n        \"num_unique_values\": 52,\n        \"samples\": [\n          60,\n          47,\n          72\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe","variable_name":"df"}

    df.corr().style.background_gradient(cmap='RdBu')

    <pandas.io.formats.style.Styler at 0x7aa3e1d5e540>

    df.drop(['BloodPressure', 'SkinThickness'], axis=1, inplace=True)

    df.isna().sum()

    Pregnancies    0
    Glucose        0
    Insulin        0
    BMI            0
    Pedigree       0
    Age            0
    Outcome        0
    dtype: int64

    df.describe()

    {"summary":"{\n  \"name\": \"df\",\n  \"rows\": 8,\n  \"fields\": [\n    {\n      \"column\": \"Pregnancies\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 269.85223453356366,\n        \"min\": 0.0,\n        \"max\": 768.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          3.8450520833333335,\n          3.0,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Glucose\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 243.73802348295857,\n        \"min\": 0.0,\n        \"max\": 768.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          120.89453125,\n          117.0,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Insulin\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 350.26059167945886,\n        \"min\": 0.0,\n        \"max\": 846.0,\n        \"num_unique_values\": 7,\n        \"samples\": [\n          768.0,\n          79.79947916666667,\n          127.25\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"BMI\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 262.05117817552093,\n        \"min\": 0.0,\n        \"max\": 768.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          31.992578124999998,\n          32.0,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Pedigree\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 271.3005221658502,\n        \"min\": 0.078,\n        \"max\": 768.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          0.47187630208333325,\n          0.3725,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 260.1941178528413,\n        \"min\": 11.76023154067868,\n        \"max\": 768.0,\n        \"num_unique_values\": 8,\n        \"samples\": [\n          33.240885416666664,\n          29.0,\n          768.0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Outcome\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 271.3865920388932,\n        \"min\": 0.0,\n        \"max\": 768.0,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.3489583333333333,\n          1.0,\n          0.4769513772427971\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}","type":"dataframe"}

    hist = df.hist(figsize=(12,10))

[]

    X = df.iloc[:, :df.shape[1]-1]
    y = df.iloc[:, -1]
    X.shape, y.shape

    ((768, 6), (768,))

    X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=8)

    scaler=StandardScaler()
    X_train=scaler.fit_transform(X_train)
    X_test=scaler.transform(X_test)

    def knn(X_train,X_test,y_train,y_test,neighbors,power):
      model = KNeighborsClassifier(n_neighbors=neighbors,p=power)

      y_pred = model.fit(X_train,y_train).predict(X_test)
      print(f"Accuracy for K-Nearest Neighbors model \t: {accuracy_score(y_test,y_pred)}")

      cm = confusion_matrix(y_test,y_pred)
      print(f'''Confusion matrix :\n
      | Positive Prediction\t| Negative Prediction
      ----------------+-----------------------------+--------------------
      Positive Class  | True Positive(TP) {cm[0,0]}\t| Flase Negative(FN) {cm[0,1]}
      ----------------+-----------------------------+--------------------
      Negative CLass  | False Positive(FP) {cm[1,0]}\t| True Negative(TN) {cm[1,1]}\n''')
      cr = classification_report(y_test,y_pred)
      print('Classification report :\n', cr)

    param_grid = {
        'n_neighbors': range(1,51),
        'p':range(1,4)
    }
    grid = GridSearchCV(estimator=KNeighborsClassifier(),param_grid=param_grid,cv=5)
    grid.fit(X_train,y_train)
    grid.best_estimator_,grid.best_params_, grid.best_score_

    (KNeighborsClassifier(n_neighbors=27),
     {'n_neighbors': 27, 'p': 2},
     np.float64(0.7719845395175262))

    knn(X_train,X_test,y_train,y_test, grid.best_params_['n_neighbors'], grid.best_params_['p'])

    Accuracy for K-Nearest Neighbors model 	: 0.7987012987012987
    Confusion matrix :

      | Positive Prediction	| Negative Prediction
      ----------------+-----------------------------+--------------------
      Positive Class  | True Positive(TP) 91	| Flase Negative(FN) 11
      ----------------+-----------------------------+--------------------
      Negative CLass  | False Positive(FP) 20	| True Negative(TN) 32

    Classification report :
                   precision    recall  f1-score   support

               0       0.82      0.89      0.85       102
               1       0.74      0.62      0.67        52

        accuracy                           0.80       154
       macro avg       0.78      0.75      0.76       154
    weighted avg       0.79      0.80      0.79       154

‎

‎

‎

‎

‎
